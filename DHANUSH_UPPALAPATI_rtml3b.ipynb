{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e16a4f-55dc-4267-819b-9deb2b6ca02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "# Download the dataset\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Prepare the dataset\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "encoded_text = [char_to_int[ch] for ch in text]\n",
    "\n",
    "    # Crea\n",
    "    # te sequences and targets\n",
    "sequence_length = 20\n",
    "sequences = []\n",
    "targets = []\n",
    "for i in range(0, len(encoded_text) - sequence_length):\n",
    "    seq = encoded_text[i:i+sequence_length]\n",
    "    target = encoded_text[i+sequence_length]\n",
    "    sequences.append(seq)\n",
    "    targets.append(target)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    # Define the dataset class\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.targets[index]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "dataset = CharDataset(sequences, targets)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "    \n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.fc(output[:, -1, :])  # Take the last time step's output\n",
    "        return output\n",
    "\n",
    "# Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.gru(embedded)\n",
    "        output = self.fc(output[:, -1, :])  # Take the last time step's output\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8be1cdf-1c68-41ec-b553-a83e416e6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def train_model(model, train_loader, test_loader, device, num_epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(sequences)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        model.eval()\n",
    "        total, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in test_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                output = model(sequences)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Time: {time.time() - start_time:.2f}s')\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "032138b0-1f1e-4f9b-87d2-c371c77e7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Epoch [1/10], Loss: 1.7088, Accuracy: 53.42%, Time: 66.06s\n",
      "Epoch [2/10], Loss: 1.4859, Accuracy: 55.24%, Time: 66.98s\n",
      "Epoch [3/10], Loss: 1.4241, Accuracy: 56.11%, Time: 70.28s\n",
      "Epoch [4/10], Loss: 1.3891, Accuracy: 56.82%, Time: 72.78s\n",
      "Epoch [5/10], Loss: 1.3635, Accuracy: 57.29%, Time: 71.48s\n",
      "Epoch [6/10], Loss: 1.3449, Accuracy: 57.44%, Time: 68.48s\n",
      "Epoch [7/10], Loss: 1.3287, Accuracy: 57.60%, Time: 68.99s\n",
      "Epoch [8/10], Loss: 1.3167, Accuracy: 57.71%, Time: 69.38s\n",
      "Epoch [9/10], Loss: 1.3059, Accuracy: 57.99%, Time: 69.57s\n",
      "Epoch [10/10], Loss: 1.2965, Accuracy: 58.10%, Time: 69.92s\n",
      "\n",
      "Training GRU model...\n",
      "Epoch [1/10], Loss: 1.6985, Accuracy: 53.37%, Time: 59.73s\n",
      "Epoch [2/10], Loss: 1.5008, Accuracy: 54.72%, Time: 62.53s\n",
      "Epoch [3/10], Loss: 1.4539, Accuracy: 55.41%, Time: 62.22s\n",
      "Epoch [4/10], Loss: 1.4274, Accuracy: 56.03%, Time: 63.01s\n",
      "Epoch [5/10], Loss: 1.4116, Accuracy: 56.07%, Time: 63.24s\n",
      "Epoch [6/10], Loss: 1.3991, Accuracy: 56.61%, Time: 65.30s\n",
      "Epoch [7/10], Loss: 1.3912, Accuracy: 55.95%, Time: 57.81s\n",
      "Epoch [8/10], Loss: 1.3837, Accuracy: 56.83%, Time: 55.28s\n",
      "Epoch [9/10], Loss: 1.3778, Accuracy: 56.81%, Time: 56.07s\n",
      "Epoch [10/10], Loss: 1.3736, Accuracy: 56.70%, Time: 56.25s\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize and train the LSTM model\n",
    "input_size = len(chars)\n",
    "hidden_size = 250\n",
    "output_size = len(chars)\n",
    "num_epochs = 10\n",
    "lr = 0.005\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size)\n",
    "train_model(lstm_model, train_loader, test_loader, device, num_epochs)\n",
    "\n",
    "print(\"\\nTraining GRU model...\")\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size)\n",
    "train_model(gru_model, train_loader, test_loader, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590b38e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 534565\n",
      "Total number of parameters in the model: 409065\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in lstm_model.parameters())\n",
    "print(f'Total number of parameters in the model: {total_params}')\n",
    "\n",
    "total_params = sum(p.numel() for p in gru_model.parameters())\n",
    "print(f'Total number of parameters in the model: {total_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39205f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Epoch [1/10], Loss: 1.7107, Accuracy: 53.30%, Time: 65.11s\n",
      "Epoch [2/10], Loss: 1.4862, Accuracy: 55.37%, Time: 65.68s\n",
      "Epoch [3/10], Loss: 1.4252, Accuracy: 56.16%, Time: 65.66s\n",
      "Epoch [4/10], Loss: 1.3901, Accuracy: 56.87%, Time: 66.38s\n",
      "Epoch [5/10], Loss: 1.3654, Accuracy: 57.25%, Time: 65.98s\n",
      "Epoch [6/10], Loss: 1.3467, Accuracy: 57.34%, Time: 66.45s\n",
      "Epoch [7/10], Loss: 1.3315, Accuracy: 57.62%, Time: 68.17s\n",
      "Epoch [8/10], Loss: 1.3188, Accuracy: 57.70%, Time: 68.43s\n",
      "Epoch [9/10], Loss: 1.3078, Accuracy: 57.78%, Time: 69.26s\n",
      "Epoch [10/10], Loss: 1.2987, Accuracy: 57.92%, Time: 65.63s\n",
      "\n",
      "Training GRU model...\n",
      "Epoch [1/10], Loss: 1.6965, Accuracy: 53.36%, Time: 55.77s\n",
      "Epoch [2/10], Loss: 1.5000, Accuracy: 54.89%, Time: 56.25s\n",
      "Epoch [3/10], Loss: 1.4538, Accuracy: 55.64%, Time: 58.93s\n",
      "Epoch [4/10], Loss: 1.4276, Accuracy: 55.95%, Time: 61.82s\n",
      "Epoch [5/10], Loss: 1.4095, Accuracy: 56.35%, Time: 62.68s\n",
      "Epoch [6/10], Loss: 1.3992, Accuracy: 56.39%, Time: 62.74s\n",
      "Epoch [7/10], Loss: 1.3917, Accuracy: 56.51%, Time: 63.39s\n",
      "Epoch [8/10], Loss: 1.3838, Accuracy: 56.52%, Time: 64.25s\n",
      "Epoch [9/10], Loss: 1.3786, Accuracy: 56.81%, Time: 65.91s\n",
      "Epoch [10/10], Loss: 1.3754, Accuracy: 56.61%, Time: 62.28s\n"
     ]
    }
   ],
   "source": [
    "input_size = len(chars)\n",
    "hidden_size = 250\n",
    "output_size = len(chars)\n",
    "num_epochs = 10\n",
    "lr = 0.005\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size)\n",
    "train_model(lstm_model, train_loader, test_loader, device, num_epochs,)\n",
    "\n",
    "print(\"\\nTraining GRU model...\")\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size)\n",
    "train_model(gru_model, train_loader, test_loader, device, num_epochs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4017cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 534565\n",
      "Total number of parameters in the model: 409065\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in lstm_model.parameters())\n",
    "print(f'Total number of parameters in the model: {total_params}')\n",
    "\n",
    "total_params = sum(p.numel() for p in gru_model.parameters())\n",
    "print(f'Total number of parameters in the model: {total_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37462031",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30  \n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "encoded_text = [char_to_int[ch] for ch in text]\n",
    "\n",
    "sequences, targets = [], []\n",
    "for i in range(len(encoded_text) - sequence_length):\n",
    "    sequences.append(encoded_text[i:i+sequence_length])\n",
    "    targets.append(encoded_text[i+sequence_length])\n",
    "\n",
    "sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8)\n",
    "test_size = total_size - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 128  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5afe178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, device, num_epochs=10, lr=0.001):\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)  \n",
    "\n",
    "   \n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()  \n",
    "        total_train_loss = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  \n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, targets) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            total_train_loss += loss.item()  \n",
    "\n",
    "        average_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(average_train_loss)\n",
    "\n",
    "        \n",
    "        model.eval() \n",
    "        total_val_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device) \n",
    "                outputs = model(inputs) \n",
    "                loss = criterion(outputs, targets) \n",
    "                total_val_loss += loss.item() \n",
    "                _, predicted = torch.max(outputs.data, 1) \n",
    "                total_correct += (predicted == targets).sum().item()  \n",
    "\n",
    "        average_val_loss = total_val_loss / len(test_loader)\n",
    "        val_accuracy = (total_correct / len(test_loader.dataset)) * 100\n",
    "        val_losses.append(average_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {average_train_loss:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(f'Total training time: {training_time:.2f} seconds')\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies, training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f275ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Epoch 1/10, Train Loss: 1.7067, Val Loss: 1.5456, Val Accuracy: 53.28%\n",
      "Epoch 2/10, Train Loss: 1.4856, Val Loss: 1.4723, Val Accuracy: 55.19%\n",
      "Epoch 3/10, Train Loss: 1.4255, Val Loss: 1.4353, Val Accuracy: 56.09%\n",
      "Epoch 4/10, Train Loss: 1.3897, Val Loss: 1.4109, Val Accuracy: 56.52%\n",
      "Epoch 5/10, Train Loss: 1.3655, Val Loss: 1.3987, Val Accuracy: 57.02%\n",
      "Epoch 6/10, Train Loss: 1.3450, Val Loss: 1.3904, Val Accuracy: 57.16%\n",
      "Epoch 7/10, Train Loss: 1.3297, Val Loss: 1.3840, Val Accuracy: 57.36%\n",
      "Epoch 8/10, Train Loss: 1.3169, Val Loss: 1.3765, Val Accuracy: 57.51%\n",
      "Epoch 9/10, Train Loss: 1.3058, Val Loss: 1.3745, Val Accuracy: 57.52%\n",
      "Epoch 10/10, Train Loss: 1.2957, Val Loss: 1.3672, Val Accuracy: 57.99%\n",
      "Total training time: 1344.54 seconds\n",
      "\n",
      "Training GRU model...\n",
      "Epoch 1/10, Train Loss: 1.6957, Val Loss: 1.5506, Val Accuracy: 52.83%\n",
      "Epoch 2/10, Train Loss: 1.5028, Val Loss: 1.4971, Val Accuracy: 54.52%\n",
      "Epoch 3/10, Train Loss: 1.4560, Val Loss: 1.4672, Val Accuracy: 55.28%\n",
      "Epoch 4/10, Train Loss: 1.4312, Val Loss: 1.4546, Val Accuracy: 55.44%\n",
      "Epoch 5/10, Train Loss: 1.4153, Val Loss: 1.4471, Val Accuracy: 55.82%\n",
      "Epoch 6/10, Train Loss: 1.4026, Val Loss: 1.4396, Val Accuracy: 55.98%\n",
      "Epoch 7/10, Train Loss: 1.3955, Val Loss: 1.4301, Val Accuracy: 56.31%\n",
      "Epoch 8/10, Train Loss: 1.3881, Val Loss: 1.4269, Val Accuracy: 56.23%\n",
      "Epoch 9/10, Train Loss: 1.3823, Val Loss: 1.4299, Val Accuracy: 56.06%\n",
      "Epoch 10/10, Train Loss: 1.3784, Val Loss: 1.4292, Val Accuracy: 56.06%\n",
      "Total training time: 913.85 seconds\n",
      "\n",
      "Comparison of LSTM and GRU models:\n",
      "LSTM - Train Loss: 1.2957, Val Loss: 1.3672, Val Accuracy: 57.99%, Training Time: 1344.54 seconds, Model Size: 559681 parameters\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gru_train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mComparison of LSTM and GRU models:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_train_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_val_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_val_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Training Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_training_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds, Model Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_model_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRU - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgru_train_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgru_val_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgru_val_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Training Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgru_training_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds, Model Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgru_model_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gru_train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size, hidden_size, output_size = len(chars), 256, len(chars)\n",
    "num_epochs, lr = 10, 0.001\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size).to(device) \n",
    "\n",
    "lstm_metrics = train_model(lstm_model, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "\n",
    "lstm_train_losses, lstm_val_losses, lstm_val_acc, lstm_training_time = lstm_metrics\n",
    "lstm_model_size = sum(p.numel() for p in lstm_model.parameters() if p.requires_grad) \n",
    "\n",
    "\n",
    "print(\"\\nTraining GRU model...\")\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "gru_metrics = train_model(gru_model, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "gru_train_losses, gru_val_losses, gru_val_acc, gru_training_time = gru_metrics\n",
    "gru_model_size = sum(p.numel() for p in gru_model.parameters() if p.requires_grad)  \n",
    "\n",
    "\n",
    "print(\"\\nComparison of LSTM and GRU models:\")\n",
    "print(f\"LSTM - Train Loss: {lstm_train_losses[-1]:.4f}, Val Loss: {lstm_val_losses[-1]:.4f}, Val Accuracy: {lstm_val_acc[-1]:.2f}%, Training Time: {lstm_training_time:.2f} seconds, Model Size: {lstm_model_size} parameters\")\n",
    "print(f\"GRU - Train Loss: {gru_train_losses[-1]:.4f}, Val Loss: {gru_val_losses[-1]:.4f}, Val Accuracy: {gru_val_acc[-1]:.2f}%, Training Time: {gru_training_time:.2f} seconds, Model Size: {gru_model_size} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1aa526a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_losses, lstm_val_losses, lstm_val_acc, lstm_training_time = lstm_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "253ea3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU - Train Loss: 1.3784, Val Loss: 1.4292, Val Accuracy: 56.06%, Training Time: 913.85 seconds, Model Size: 428097 parameters\n"
     ]
    }
   ],
   "source": [
    "gru_train_losses, gru_val_losses, gru_val_acc, gru_training_time = gru_metrics\n",
    "print(f\"GRU - Train Loss: {gru_train_losses[-1]:.4f}, Val Loss: {gru_val_losses[-1]:.4f}, Val Accuracy: {gru_val_acc[-1]:.2f}%, Training Time: {gru_training_time:.2f} seconds, Model Size: {gru_model_size} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8b56ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Epoch 1/10, Train Loss: 1.8172, Val Loss: 1.6266, Val Accuracy: 51.31%\n",
      "Epoch 2/10, Train Loss: 1.5672, Val Loss: 1.5412, Val Accuracy: 53.40%\n",
      "Epoch 3/10, Train Loss: 1.5032, Val Loss: 1.5037, Val Accuracy: 54.46%\n",
      "Epoch 4/10, Train Loss: 1.4679, Val Loss: 1.4781, Val Accuracy: 55.16%\n",
      "Epoch 5/10, Train Loss: 1.4441, Val Loss: 1.4631, Val Accuracy: 55.45%\n",
      "Epoch 6/10, Train Loss: 1.4271, Val Loss: 1.4527, Val Accuracy: 55.61%\n",
      "Epoch 7/10, Train Loss: 1.4127, Val Loss: 1.4455, Val Accuracy: 56.09%\n",
      "Epoch 8/10, Train Loss: 1.4021, Val Loss: 1.4400, Val Accuracy: 56.09%\n",
      "Epoch 9/10, Train Loss: 1.3928, Val Loss: 1.4326, Val Accuracy: 56.13%\n",
      "Epoch 10/10, Train Loss: 1.3848, Val Loss: 1.4272, Val Accuracy: 56.43%\n",
      "Total training time: 477.24 seconds\n",
      "\n",
      "Training GRU model...\n",
      "Epoch 1/10, Train Loss: 1.7944, Val Loss: 1.6224, Val Accuracy: 51.36%\n",
      "Epoch 2/10, Train Loss: 1.5687, Val Loss: 1.5527, Val Accuracy: 53.24%\n",
      "Epoch 3/10, Train Loss: 1.5144, Val Loss: 1.5170, Val Accuracy: 54.04%\n",
      "Epoch 4/10, Train Loss: 1.4856, Val Loss: 1.5000, Val Accuracy: 54.46%\n",
      "Epoch 5/10, Train Loss: 1.4672, Val Loss: 1.4872, Val Accuracy: 54.92%\n",
      "Epoch 6/10, Train Loss: 1.4540, Val Loss: 1.4753, Val Accuracy: 55.16%\n",
      "Epoch 7/10, Train Loss: 1.4441, Val Loss: 1.4720, Val Accuracy: 55.18%\n",
      "Epoch 8/10, Train Loss: 1.4360, Val Loss: 1.4702, Val Accuracy: 55.30%\n",
      "Epoch 9/10, Train Loss: 1.4299, Val Loss: 1.4618, Val Accuracy: 55.56%\n",
      "Epoch 10/10, Train Loss: 1.4253, Val Loss: 1.4578, Val Accuracy: 55.56%\n",
      "Total training time: 460.77 seconds\n",
      "\n",
      "Comparison of LSTM and GRU models:\n",
      "LSTM - Train Loss: 1.3848, Val Loss: 1.4272, Val Accuracy: 56.43%, Training Time: 477.24 seconds, Model Size: 148801 parameters\n",
      "GRU - Train Loss: 1.4253, Val Loss: 1.4578, Val Accuracy: 55.56%, Training Time: 460.77 seconds, Model Size: 115777 parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size, hidden_size, output_size = len(chars), 128, len(chars)\n",
    "num_epochs, lr = 10, 0.001\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size).to(device) \n",
    "\n",
    "lstm_metrics = train_model(lstm_model, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "\n",
    "lstm_train_losses, lstm_val_losses, lstm_val_acc, lstm_training_time = lstm_metrics\n",
    "lstm_model_size = sum(p.numel() for p in lstm_model.parameters() if p.requires_grad) \n",
    "\n",
    "\n",
    "print(\"\\nTraining GRU model...\")\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "gru_metrics = train_model(gru_model, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "gru_train_losses, gru_val_losses, gru_val_acc, gru_training_time = gru_metrics\n",
    "gru_model_size = sum(p.numel() for p in gru_model.parameters() if p.requires_grad)  \n",
    "\n",
    "\n",
    "print(\"\\nComparison of LSTM and GRU models:\")\n",
    "print(f\"LSTM - Train Loss: {lstm_train_losses[-1]:.4f}, Val Loss: {lstm_val_losses[-1]:.4f}, Val Accuracy: {lstm_val_acc[-1]:.2f}%, Training Time: {lstm_training_time:.2f} seconds, Model Size: {lstm_model_size} parameters\")\n",
    "print(f\"GRU - Train Loss: {gru_train_losses[-1]:.4f}, Val Loss: {gru_val_losses[-1]:.4f}, Val Accuracy: {gru_val_acc[-1]:.2f}%, Training Time: {gru_training_time:.2f} seconds, Model Size: {gru_model_size} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28947f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "encoded_text = [char_to_int[ch] for ch in text]\n",
    "\n",
    "sequences, targets = [], []\n",
    "for i in range(len(encoded_text) - sequence_length):\n",
    "    sequences.append(encoded_text[i:i+sequence_length])\n",
    "    targets.append(encoded_text[i+sequence_length])\n",
    "\n",
    "sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8)\n",
    "test_size = total_size - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 128  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8968a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Epoch 1/10, Train Loss: 1.8213, Val Loss: 1.6333, Val Accuracy: 51.42%\n",
      "Epoch 2/10, Train Loss: 1.5723, Val Loss: 1.5441, Val Accuracy: 53.51%\n",
      "Epoch 3/10, Train Loss: 1.5064, Val Loss: 1.5040, Val Accuracy: 54.32%\n",
      "Epoch 4/10, Train Loss: 1.4695, Val Loss: 1.4780, Val Accuracy: 55.14%\n",
      "Epoch 5/10, Train Loss: 1.4450, Val Loss: 1.4605, Val Accuracy: 55.64%\n",
      "Epoch 6/10, Train Loss: 1.4270, Val Loss: 1.4492, Val Accuracy: 55.85%\n",
      "Epoch 7/10, Train Loss: 1.4124, Val Loss: 1.4401, Val Accuracy: 55.97%\n",
      "Epoch 8/10, Train Loss: 1.4013, Val Loss: 1.4347, Val Accuracy: 56.26%\n",
      "Epoch 9/10, Train Loss: 1.3915, Val Loss: 1.4258, Val Accuracy: 56.56%\n",
      "Epoch 10/10, Train Loss: 1.3835, Val Loss: 1.4231, Val Accuracy: 56.67%\n",
      "Total training time: 499.12 seconds\n",
      "\n",
      "Training GRU model...\n",
      "Epoch 1/10, Train Loss: 1.7945, Val Loss: 1.6201, Val Accuracy: 51.64%\n",
      "Epoch 2/10, Train Loss: 1.5687, Val Loss: 1.5489, Val Accuracy: 53.39%\n",
      "Epoch 3/10, Train Loss: 1.5148, Val Loss: 1.5163, Val Accuracy: 54.24%\n",
      "Epoch 4/10, Train Loss: 1.4859, Val Loss: 1.4988, Val Accuracy: 54.60%\n",
      "Epoch 5/10, Train Loss: 1.4672, Val Loss: 1.4907, Val Accuracy: 54.76%\n",
      "Epoch 6/10, Train Loss: 1.4536, Val Loss: 1.4752, Val Accuracy: 55.38%\n",
      "Epoch 7/10, Train Loss: 1.4433, Val Loss: 1.4691, Val Accuracy: 55.42%\n",
      "Epoch 8/10, Train Loss: 1.4351, Val Loss: 1.4687, Val Accuracy: 55.48%\n",
      "Epoch 9/10, Train Loss: 1.4278, Val Loss: 1.4613, Val Accuracy: 55.72%\n",
      "Epoch 10/10, Train Loss: 1.4225, Val Loss: 1.4542, Val Accuracy: 55.80%\n",
      "Total training time: 452.94 seconds\n",
      "\n",
      "Comparison of LSTM and GRU models:\n",
      "LSTM - Train Loss: 1.3835, Val Loss: 1.4231, Val Accuracy: 56.67%, Training Time: 499.12 seconds, Model Size: 148801 parameters\n",
      "GRU - Train Loss: 1.4225, Val Loss: 1.4542, Val Accuracy: 55.80%, Training Time: 452.94 seconds, Model Size: 115777 parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size, hidden_size, output_size = len(chars), 128, len(chars)\n",
    "num_epochs, lr = 10, 0.001\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size).to(device) \n",
    "\n",
    "lstm_metrics = train_model(lstm_model, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "\n",
    "lstm_train_losses, lstm_val_losses, lstm_val_acc, lstm_training_time = lstm_metrics\n",
    "lstm_model_size = sum(p.numel() for p in lstm_model.parameters() if p.requires_grad) \n",
    "\n",
    "\n",
    "print(\"\\nTraining GRU model...\")\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "gru_metrics = train_model(gru_model, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "gru_train_losses, gru_val_losses, gru_val_acc, gru_training_time = gru_metrics\n",
    "gru_model_size = sum(p.numel() for p in gru_model.parameters() if p.requires_grad)  \n",
    "\n",
    "\n",
    "print(\"\\nComparison of LSTM and GRU models:\")\n",
    "print(f\"LSTM - Train Loss: {lstm_train_losses[-1]:.4f}, Val Loss: {lstm_val_losses[-1]:.4f}, Val Accuracy: {lstm_val_acc[-1]:.2f}%, Training Time: {lstm_training_time:.2f} seconds, Model Size: {lstm_model_size} parameters\")\n",
    "print(f\"GRU - Train Loss: {gru_train_losses[-1]:.4f}, Val Loss: {gru_val_losses[-1]:.4f}, Val Accuracy: {gru_val_acc[-1]:.2f}%, Training Time: {gru_training_time:.2f} seconds, Model Size: {gru_model_size} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a131923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
